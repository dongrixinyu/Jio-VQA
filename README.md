# Jio-VQA
A benchmark for Visual Question Answering, developed by `jiojio`, serves as a valuable resource for both training and evaluation purposes.

As you may be aware, the current state of VQA technology falls short of fulfilling the diverse needs of human users. The primary reasons for this gap include:

- The VQA model architecture has yet to achieve a truly end-to-end evolution, limiting its ability to process the complex information present in images.
- There is a scarcity of datasets that accurately reflect the needs and nuances of human users.

Given my dissatisfaction with the status quo of VQA models, I am motivated to contribute a benchmark derived entirely from everyday practical applications.

# How to use

```
$ git clone https://github.com/dongrixinyu/Jio-VQA
$ cd Jio-VQA
$ python 
```
